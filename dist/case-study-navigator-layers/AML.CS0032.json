{
    "versions": {
        "layer": "4.3",
        "navigator": "4.6.4"
    },
    "domain": "atlas-atlas",
    "metadata": [
        {
            "name": "url",
            "value": "https://atlas.mitre.org/studies/AML.CS0032"
        },
        {
            "name": "atlas_data_version",
            "value": "5.0.1"
        }
    ],
    "name": "Attempted Evasion of ML Phishing Webpage Detection System",
    "description": "Adversaries create phishing websites that appear visually similar to legitimate sites. These sites are designed to trick users into entering their credentials, which are then sent to the bad actor. To combat this behavior, security companies utilize AI/ML-based approaches to detect phishing sites and block them in their endpoint security products.\n\nIn this incident, adversarial examples were identified in the logs of a commercial machine learning phishing website detection system. The detection system makes an automated block/allow determination from the \"phishing score\" of an ensemble of image classifiers each responsible for different phishing indicators (visual similarity, input form detection, etc.). The adversarial examples appeared to employ several simple yet effective strategies for manually modifying brand logos in an attempt to evade image classification models. The phishing websites which employed logo modification methods successfully evaded the model responsible detecting brand impersonation via visual similarity. However, the other components of the system successfully flagged the phishing websites.",
    "techniques": [
        {
            "techniqueID": "AML.T0043.003",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0043",
            "showSubtechniques": true,
            "tactic": "ai-attack-staging"
        },
        {
            "techniqueID": "AML.T0015",
            "showSubtechniques": false,
            "tactic": "defense-evasion",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0052",
            "showSubtechniques": false,
            "tactic": "initial-access",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0048.003",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0048",
            "showSubtechniques": true,
            "tactic": "impact"
        }
    ],
    "legendItems": [
        {
            "label": "Used in case study",
            "color": "#C8E6C9"
        }
    ]
}